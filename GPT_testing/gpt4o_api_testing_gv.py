from openai import OpenAI
from google.cloud import vision
import io
import PyPDF2
import os

# setup openai api key
openai_client = OpenAI(
    api_key='sk-DaQ7ivxveeVp9VHjbn4CxhN4xLtB8PnO-NM5fGIIQjT3BlbkFJ4aFykXZzJuh38UiwlUdtJbasG5lw_-UhupTWzNfy0A'
)

# setup google cloud vision api
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = '/Users/rahuldmello/Desktop/Co-op/AI_testing/GPT4_testing/gpt-testing-431616-7a9b204deef1.json'
client = vision.ImageAnnotatorClient()


def get_image_description(image_path):
    """
    Analyze the image and return a description using Google cloud vision

    :param image_path: Path to image file
    :return: Description of image
    """
    with io.open(image_path, 'rb') as image_file:
        content = image_file.read()

        image = vision.Image(content=content)

        # perform label detection
        label_response = client.label_detection(image=image)
        labels = label_response.label_annotations
        label_descriptions = ', '.join(label.description for label in labels)

        # perform text detection
        text_response = client.text_detection(image=image)
        texts = text_response.text_annotations
        text_descriptions = ' '.join(text.description for text in texts)

        # perform object detection
        object_response = client.object_localization(image=image)
        objects = object_response.localized_object_annotations
        object_descriptions = ', '.join(object.name for object in objects)

        # perform web detection (to capture any relevant web entities)
        web_response = client.web_detection(image=image)
        web_entities = web_response.web_detection.web_entities
        web_descriptions = ', '.join(entity.description for entity in web_entities if entity.description)

        # combine and clean up descriptions
        combined_description = (
            f"Labels: {label_descriptions}. "
            f"Detected Text: {text_descriptions}. "
            f"Objects: {object_descriptions}. "
            f"Web Entities: {web_descriptions}."
        )

        # remove any redundant or empty descriptions
        combined_description = ". ".join(filter(None, combined_description.split('. ')))

        return combined_description


def extract_text_from_pdf(pdf_path):
    """
    Extract text from pdf file
    :param pdf_path: path to pdf file
    :return: extracted text
    """
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        text = ''
        for page in reader.pages:
            text += page.extract_text()

    return text


def generate_image_descriptions(image_description, guidelines):
    """
    Generate title, abstract, and subjects based on the image description and guidelines

    :param image_description: description of image as generated by Google Vision
    :param guidelines: guidelines for generating title and abstracts
    :return: Generated title, abstract, and subjects
    """

    response = openai_client.chat.completions.create(
        messages=[
            {"role": "system", "content": f"You are an expert in library collections. Follow these guidelines strictly: {guidelines}"},
            {"role": "user", "content": f"Description: {image_description}. Please provide a title, and abstract, and subjects (or keywords)."}
        ],
        model='gpt-4o-mini',
    )

    return response.choices[0].message.content


# paths
image_path = '/Users/rahuldmello/Desktop/Co-op/AI_testing/GPT4_testing/neu_126306.jpg'
pdf_path = '/Users/rahuldmello/Desktop/Co-op/AI_testing/GPT4_testing/Photograph_metadata_guidelines.pdf'

# extract image description
image_description = get_image_description(image_path)

# extract guidelines from pdf
guidelines = extract_text_from_pdf(pdf_path)

# generate title, abstract, and subjects
metadata = generate_image_descriptions(image_description, guidelines)

print(f'Image Description: {image_description}')
print(f'Generated Metadata: \n{metadata}')



