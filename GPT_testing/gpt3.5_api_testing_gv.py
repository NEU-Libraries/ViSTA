from openai import OpenAI
from google.cloud import vision
import io
import PyPDF2
import os

# setup openai api key
openai_client = OpenAI(
    api_key='sk-DaQ7ivxveeVp9VHjbn4CxhN4xLtB8PnO-NM5fGIIQjT3BlbkFJ4aFykXZzJuh38UiwlUdtJbasG5lw_-UhupTWzNfy0A'
)

# setup google cloud vision api
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = '/Users/rahuldmello/Desktop/Co-op/AI_testing/GPT4_testing/gpt-testing-431616-7a9b204deef1.json'
client = vision.ImageAnnotatorClient()


def get_image_description(image_path):
    """
    Analyze the image and return a description using Google cloud vision

    :param image_path: Path to image file
    :return: Description of image
    """
    with io.open(image_path, 'rb') as image_file:
        content = image_file.read()

        image = vision.Image(content=content)
        response = client.label_detection(image=image)
        labels = response.label_annotations

        description = ', '.join(label.description for label in labels)
        return description


def extract_text_from_pdf(pdf_path):
    """
    Extract text from pdf file
    :param pdf_path: path to pdf file
    :return: extracted text
    """
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        text = ''
        for page in reader.pages:
            text += page.extract_text()

    return text


def generate_image_descriptions(image_description, guidelines):
    """
    Generate title, abstract, and subjects based on the image description and guidelines

    :param image_description: description of image as generated by Google Vision
    :param guidelines: guidelines for generating title and abstracts
    :return: Generated title, abstract, and subjects
    """

    response = openai_client.chat.completions.create(
        messages=[
            {"role": "system", "content": f"You are an expert in library collections. Follow these guidelines strictly: {guidelines}"},
            {"role": "user", "content": f"Description: {image_description}. Please provide a title, and abstract, and subjects (or keywords)."}
        ],
        model='gpt-3.5-turbo',
    )

    return response.choices[0].message.content


# paths
image_path = '/Users/rahuldmello/Desktop/Co-op/AI_testing/GPT4_testing/neu_126321.jpg'
pdf_path = '/Users/rahuldmello/Desktop/Co-op/AI_testing/GPT4_testing/Photograph_metadata_guidelines.pdf'

# extract image description
image_description = get_image_description(image_path)

# extract guidelines from pdf
guidelines = extract_text_from_pdf(pdf_path)

# generate title, abstract, and subjects
metadata = generate_image_descriptions(image_description, guidelines)

print(f'Image Description: {image_description}')
print(f'Generated Metadata: \n{metadata}')



